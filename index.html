<!doctype html>
<html lang="en">
<head>
<title>Erasing Concepts from Diffusion Models</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<meta name="description" content="Updating thousands of memories in GPT by directly calculating parameter changes." />
<meta property="og:title" content="Erasing Concepts from Diffusion Models" />
<meta property="og:description" content="Updating thousands of memories in GPT by directly calculating parameter changes." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="twitter:title" content="Erasing Concepts from Diffusion Models" />
<meta name="twitter:description" content="Updating thousands of memories in GPT by directly calculating parameter changes." />
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Math&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

<style>
.relatedthumb {
  float:left; width: 200px; margin: 3px 10px 7px 0;
}
.relatedblock {
  clear: both;
  display: inline-block;
}
.bold-sc {
  font-variant: small-caps;
  font-weight: bold;
}
.cite, .citegroup {
  margin-bottom: 8px;
}
:target {
  background-color: yellow;
}
</style>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FD12LWN557"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date()); gtag('config', 'G-FD12LWN557');
</script>

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">Erasing Concepts</nobr>
 from
 <nobr class="widenobr">Diffusion Models</nobr>
 </h1>
<address>
  <nobr><a href="https://rohitgandikota.github.io/" target="_blank"
  >Rohit Gandikota</a><sup>1</sup>,</nobr>
  <nobr><a href="https://joaanna.github.io/" target="_blank"
  >Joanna Materzy&#324;ska</a><sup>2</sup>,</nobr>
  <nobr><a href="https://github.com/JadenFiotto-Kaufman" target="_blank"
  >Jaden Fiotto-Kaufman</a><sup>1</sup>,</nobr>
  <nobr><a href="https://baulab.info/" target="_blank"
  >David Bau</a><sup>1</sup></nobr>
 <br>
  <nobr><sup>1</sup><a href="https://khoury.northeastern.edu/" target="_blank"
  >Northeastern University</a>,</nobr>
  <nobr><sup>2</sup><a href="https://www.csail.mit.edu/" target="_blank"
  >MIT CSAIL</a></nobr>
</address>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row justify-content-center text-center">

<p>
<a href="https://arxiv.org/pdf/2303.07345.pdf" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/paper-thumb.png" style="border:1px solid; margin: 0 38px;" alt="ArXiv Preprint thumbnail" data-nothumb=""><br>ArXiv<br>Preprint</a>
<a href="https://github.com/rohitgandikota/erasing" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/code-thumb.png" style="border:1px solid; margin: 0 38px;" alt="Github code thumbnail" data-nothumb=""><br>Source Code<br>Github</a>
</p>

<div class="card" style="max-width: 1020px;">
<div class="card-block">
<h3>How to erase concepts from diffusion model weights?</h3>
<p>
<p>With the recent advancements in image generation quality, there is a growing concern for safety, privacy and copyrighted content 
  in diffusion model generated images. From inappropriate content generation to artistic style mimicing, recent works attempt to restrict such content
  via inference methods or post generation classification restriction. Such methods can be easily circumvented when users have access to open source weights.
</p>
<p>
In this paper, we propose a model weights fine-tuning to <b>erase concepts from diffusion models using their own knowledge</b>. Given just the text of the concept
  to be erased, our method can edit the model weights to erase the concept while keeping the inteference with other concepts minimal. This type of fine-tuning
  has an advantage over inference methods where it is difficult to circumvent even with open-sourced weights while avoiding the expense of retraining the data 
  on filtered training dataset.
</p>
</div><!--card-block-->
</div><!--card-->

</div><!--row-->
  
<div class="row">
<div class="col">
  
<figure class="center_image" style="margin-top: 30px">
  <img src="images/paper/main.png" style="width:100%; max-width:800px">
  <figcaption> Our method can be used to erase a wide variety of concepts including nudity, art styles or even objects permanently from the model weights.
  </figcaption>
</figure>

  <h2> Why erase concepts from diffusion model? </h2>
  <p> Large scale image generation models like stable-diffusion have the capability to generate hyper realistic content. Since they mimic the knowledge
    of the training dataset, they are also capable of generating nudity, mimic particular artistic styles, generate undesired objects. This could be of a
    concern to institutions hosting the APIs or releasing their models for research. </p>
    <p class="citation"><a href="https://www.washingtonpost.com/comics/2023/02/14/ai-in-illustration/"><img src="images/articles/art_washington.jpeg" alt="washingtonpost-2023">Michael Cavna, "Artists are alarmed by AI - and they're fighting back", Washington Post, Feb 14 2023 </a><br>
    <p class="citation"><a href="https://www.theverge.com/2023/2/6/23587393/ai-art-copyright-lawsuit-getty-images-stable-diffusion"><img src="images/articles/getty_verge.png" alt="verge-2023">James Vincent, "Getty Images sues AI art generator Stable Diffusion in the US for copyright infringement", The Verge, Feb 06 2023 </a><br>
 <p>   
    There are methods to mitigate such content post production or during inference, but are easy to bipass. We propose finetuning the weights for a small 
      number of iterations using simply the text description of such concepts and erase them permanently from the weights. 
  </p>
  
<h2> How to erase concepts from the model? </h2>
  <p> We simply use the vast knowledge of the model itself to unlearn a particular concept. Instead of collecting a dataset of images corresponding to the concept
    that one intends to erase, we propose using the generative capabilities of the pre-trained model. </p>
  
  <figure class="center_image" style="margin-top: 30px">
    <img src="images/paper/esd.png" style="width:100%; max-width:800px">
    <figcaption> The ESD model is fine-tuned with the conditioned and unconditioned 
      scores obtained from frozen SD model to guide the output away from the concept being erased. 
      The model learns from itâ€™s own knowledge to steer the diffusion process away from the undesired concept.
    </figcaption>
  </figure>
  
  From the frozen pre-trained, we query the noise for a given prompt, and train the edited model to guide in the opposite direction using classifier free guidance.
  We fine-tune the model weights such that the edited model always generates images away from the concept that is erased. 
  </p>
  
<h2> What weights to edit? </h2>
  <p>
    Cross attentions act as a gateway for text conditioning in the image generation process. Naturally, these attention heads activate when a certain token 
    is present in the text prompt. Where as self attentions are active irrrespective of the text conditioning. They attend to the visual aspect of a concept. 
  </p>
  <figure class="center_image" style="margin-top: 30px">
    <img src="images/paper/attentions.png" style="width:100%; max-width:800px">
    <figcaption> Cross attentions activate only when <b><i>"car"</i></b> is present in the prompt. But self attentions are activate in both the cases.
    </figcaption>
  </figure>
    
  <p>
    With this evidence, we propose ESD-x, finetuning cross attention to erase a concept. This has a very narrow effect on the distribution, especially when
    the concept is mentioned in the prompt. Such finer effect is desirable in case of art erase, where not all artists would want their styles to be erased.
    ESD-u, finetuning all the unconditional layers (all layers except cross attentions) for a more generalised, unconditional and global erasure effect.
  </p>   
  <figure class="center_image" style="margin-top: 30px">
    <img src="images/paper/ablation.png" style="width:100%; max-width:800px">
    <figcaption> ESD-x (last column) erases in a narrow, finer scope while keeping the interference (last 3 rows) to minimal. Where as ESD-u (third column) erases in a global fashion.
    </figcaption>
  </figure>
  
 <h3> Artist Style Erasure </h3>
      <p> With the concern arising from recent lawsuits, artistic style erasure can be of interest for many artists and organizations. Since this is a more
        sensitive erasure where specific art styles need to be erased while keeping the interference to minimal, we propose ESD-x for this application
      </p>
      <figure class="center_image" style="margin-top: 30px">
        <img src="images/paper/artstyle.png" style="width:100%; max-width:800px">
        <figcaption> Our method erases a style more prominently while keeping the undesired interference to a minimal. 
          The blue dotted images represent the intended erasure while the off-diagonal images represent undesired interference. 
        </figcaption>
      </figure>
  
  <h3> Nudity Erasure </h3>
    <p> Since nudity content can be generated without explicitly mentioning the word <i>"nudity"</i>, we propose using ESD-u. Compared the inference 
      techniques, our method has a much aggresive erasure effect on a dataset that explicitly creates innapropriate content. </p>
    <figure class="center_image" style="margin-top: 30px">
      <img src="images/paper/nudity.png" style="width:100%; max-width:800px">
      <figcaption> Our method erases nudity across all the categories more significantly compared to inference techniques (SLD)
        and models like Stable diffusion V2.0 that is trained on NSFW filtered datasets.
      </figcaption>
    </figure>
      
  
  <h3> Object Erasure </h3>
      <p> Erasing undesired objects can also be done using ESD-u, since the effect requires to be global and not text specific </p>

<h2> Limitations </h2>
      <p> 
        For both NSFW erasure and artistic style erasure, we find that our method is more effective than baseline approaches on erasing the targeted visual 
        concept, but when erasing large concepts such as entire object classes or some particular styles,
        our method can impose a trade-off between complete erasure of a visual concept and interference with other visual concepts. </p>     
      <figure class="center_image" style="margin-top: 30px">
        <img src="images/paper/limitations.png" style="width:100%; max-width:800px">
        <figcaption> Cases of incomplete concept erasures and style interference with our method.
        </figcaption>
      </figure>
       
<h2>How to cite</h2>

<p>The preprint can be cited as follows.
</p>

<div class="card">
<h3 class="card-header">bibliography</h3>
<div class="card-block">
<p style="text-indent: -3em; margin-left: 3em;" class="card-text clickselect">
Rohit Gandikota, Joanna Materzy&#324;ska, Jaden Fiotto-Kaufman, David Bau. "<em>Erasing Concepts from Diffusion Models.</em>" arXiv preprint <nobr><a href="https://arxiv.org/abs/2303.07345">arXiv:2303.07345</a> (2023).</nobr>
</p>
</div>
<h3 class="card-header">bibtex</h3>
<div class="card-block">
<pre class="card-text clickselect">
@article{gandikota2023erasing,
  title={Erasing Concepts from Diffusion Models},
  author={Rohit Gandikota and Joanna Materzy\'nska and Jaden Fiotto-Kaufman and David Bau},
  journal={arXiv preprint arXiv:2303.07345},
  year={2023}
}
</pre>
</div>
</div>
</p>

</div>
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://baulab.info/">About the Bau Lab</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
</script>
</html>

