<!doctype html>
<html lang="en">
<head>
<title>Erasing Concepts from Diffusion Models</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<meta name="description" content="Erasing undesired capabilities from a diffusion model using a fast data-free fine-tuning process." />
<meta property="og:title" content="Erasing Concepts from Diffusion Models" />
<meta property="og:description" content="Erasing undesired capabilities from a diffusion model using a fast data-free fine-tuning process." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="twitter:title" content="Erasing Concepts from Diffusion Models" />
<meta name="twitter:description" content="Erasing undesired capabilities from a diffusion model using a fast data-free fine-tuning process." />
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Math&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

<style>
.relatedthumb {
  float:left; width: 200px; margin: 3px 10px 7px 0;
}
.relatedblock {
  clear: both;
  display: inline-block;
}
.bold-sc {
  font-variant: small-caps;
  font-weight: bold;
}
.cite, .citegroup {
  margin-bottom: 8px;
}
:target {
  background-color: yellow;
}
</style>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FD12LWN557"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date()); gtag('config', 'G-FD12LWN557');
</script>

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">Erasing Concepts</nobr>
 from
 <nobr class="widenobr">Diffusion Models</nobr>
 </h1>
<address>
  <nobr><a href="https://rohitgandikota.github.io/" target="_blank"
  >Rohit Gandikota</a><sup>*1</sup>,</nobr>
  <nobr><a href="https://joaanna.github.io/" target="_blank"
  >Joanna Materzy&#324;ska</a><sup>*2</sup>,</nobr>
  <nobr><a href="https://github.com/JadenFiotto-Kaufman" target="_blank"
  >Jaden Fiotto-Kaufman</a><sup>1</sup>,</nobr>
  <nobr><a href="https://baulab.info/" target="_blank"
  >David Bau</a><sup>1</sup></nobr>
 <br>
  <nobr><sup>1</sup><a href="https://khoury.northeastern.edu/" target="_blank"
  >Northeastern University</a>,</nobr>
  <nobr><sup>2</sup><a href="https://www.csail.mit.edu/" target="_blank"
  >MIT CSAIL</a></nobr>;
<nobr><sup>*</sup>Equal contribution</nobr>

</address>
<center>
  International Conference on Computer Vision
  <a href="https://iccv2023.thecvf.com/">(ICCV 2023)</a>
</center>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row justify-content-center text-center">

<div class="row justify-content-center" style="margin-bottom: 20px">
<p class="text-center">
<a href="https://unified.baulab.info/"
   >Update!  See our <b>UCE</b> paper that scales erasing and unifies with debiasing<br>
           Unified Concept Editing in Diffusion Models (WACV 2024)</a>
</p>
</div>
<p>
<a href="https://arxiv.org/pdf/2303.07345.pdf" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/paper-thumb.png" style="border:1px solid; margin: 0 38px;" alt="ArXiv Preprint thumbnail" data-nothumb=""><br>ArXiv<br>Preprint</a>
<a href="https://github.com/rohitgandikota/erasing" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/code-thumb.png" style="border:1px solid; margin: 0 38px;" alt="Github code thumbnail" data-nothumb=""><br>Source Code<br>Github</a>
<a href="https://erasing.baulab.info/weights/esd_models/" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/data-thumb.png" style="border:1px solid; margin: 0 38px;" alt="Data thumbnail" data-nothumb=""><br>Fine-Tuned<br>Model  Weights</a>
<a href="https://huggingface.co/spaces/baulab/Erasing-Concepts-In-Diffusion" class="d-inline-block p-3 align-bottom" target="_blank"><img height="78" width="104" src="images/demo3x4-thumb.png" style="border:1px solid" alt="Huggingface demo thumbnail" data-nothumb=""><br>Huggingface<br>Demo</a>
<a href="https://erasing.baulab.info/files/iccv_erasing_demo.mp4" class="d-inline-block p-3 align-bottom" target="_blank"><img height="78" width="104" src="images/demo_thumb.png" style="border:1px solid" alt="demo video thumbnail" data-nothumb=""><br>ICCV<br>Demo</a>
<a href="https://erasing.baulab.info/files/postericcv.pdf" class="d-inline-block p-3 align-bottom" target="_blank"><img height="78" width="104" src="images/poster_thumb.png" style="border:1px solid" alt="" data-nothumb=""><br>ICCV<br>Poster</a>
</p>

<div class="card" style="max-width: 1020px;">
<div class="card-block">
<h3>How to erase concepts from diffusion model weights?</h3>
<p>
<p>With recent advancements in image generation quality, there is a growing
concern around safety, privacy and copyrighted content in diffusion-model-generated
images. Recent works attempt to restrict undesired content via inference methods or
post-generation classification, but such methods can be easily circumvented when users
have access to open-source weights.
</p>
<p>
In this paper, we propose a method for fine-tuning model weights to
<b>erase concepts from diffusion models using their own knowledge</b>.
Given just the text of the concept to be erased, our method can edit
the model weights to erase the concept while minimizing the inteference
with other concepts. This type of fine-tuning has an advantage over
previous methods: it is not easy to circumvent because it modifies weights,
yet it is fast and practical because it avoids the expense of retraining
the whole model on filtered training data.
</p>
</div><!--card-block-->
</div><!--card-->

</div><!--row-->
  
<div class="row">
<div class="col">
  
<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/main.png" style="width:100%; max-width:800px"></center>
  <figcaption> Our method can be used to erase a wide variety of concepts including nudity, art styles or even objects permanently from the model weights.
  </figcaption>
</figure>

  <h2> Why erase concepts from diffusion models? </h2>
  <p>Since large-scale models such as Stable Diffusion are trained
  to mimic vast training data sets, it is not surprising that
  they are capable of generating nudity, imitating particular artistic styles, or generating
  undesired objects.  These capabilities have led to an array of risks and economic
  impacts: use of the models to create
  <a href="https://www.washingtonpost.com/technology/2023/02/13/ai-porn-deepfakes-women-consent/"
    >deepfake porn raises issues of consent and harrassment</a>;
  their ability to
  <a href="https://www.washingtonpost.com/comics/2023/02/14/ai-in-illustration/"
    >effortlessly imitate artistic styles has led artists to sue</a>, concerned about dire
  economic consequences for their profession</a>; and their tendency to echo
  <a href="https://www.theverge.com/2023/2/6/23587393/ai-art-copyright-lawsuit-getty-images-stable-diffusion"
     >copyrighted or trademarked symbols indiscriminately</a> has drawn another lawsuit.
  Such issues are a serious concern for institutions who wish to release their models.</p>
  <p>   
  There are methods to mitigate such content post-production or during inference,
  but they are easy to bypass. We propose fine tuning the weights for a small 
  number of iterations using the text description of the targeted concepts to
  erase them permanently from the weights. 
  </p>
  
<h2> How to erase concepts from a model? </h2>
  <p>We use the encyclopedic knowledge of the model itself to unlearn a particular concept.
  Instead of collecting a new dataset of images corresponding to the concept
  that one intends to erase, we propose using the generative capabilities of the
  pre-trained model. </p>
  <p>The idea is simple but powerful: the pretrained model
  <font size="+1" style="font-family:serif"><em>P</em><sub><em>&theta;</em>*</sub>(<em>x</em>)</font>
  already has the ability to model conditional probabilities for any named concept
  <font size="+1" style="font-family:serif"><em>c</em></font>,
  so our goal is to produce a new model
  <font size="+1" style="font-family:serif"><em>P</em><sub><em>&theta;</em></sub>(<em>x</em>)</font>
  that reshapes its
  distribution by reducing the probability of any image in the conditional distribution,
  according to the original pretrained model:</p>
  <center><img src="images/paper/equation_4.png" style="width:180px;padding-bottom:10px;"></center>
  <p>This is similar to the motivation behind <a
  href="https://proceedings.neurips.cc/paper/2020/file/49856ed476ad01fcff881d57e161d73f-Paper.pdf"
  >compositional energy-based models</a>.  In diffusion it leads to a
  straightforward fine-tuning scheme that modifies the noise prediction model by
  subtracting a component conditioned on the concept to erase:
  </p>
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/esd.png" style="width:100%; max-width:800px"></center>
    <figcaption>Our Erased Stable Diffusion (ESD) method fine tunes a model using the
      conditioned and unconditioned scores obtained from the original frozen Stable Diffusion (SD)
      model, to guide the output away from the concept being erased. 
    </figcaption>
  </figure>
  
  We query the frozen pre-trained model to predict the noise for the given erasure prompt,
  then we train the edited model to guide it in the opposite direction using the
  ideas of <a href="https://arxiv.org/pdf/2207.12598.pdf"
  >classifier-free guidance</a> at training time rather than inference.
  We find that fine-tuning model weights with this objective is very effective,
  producing an edited image generator that directly avoids that concept that
  we have erased.
  </p>
  
<h2> What weights to edit? </h2>
  <p>
  Cross attention modules act as a gateway for text conditioning in the image
  generation process. Naturally, these attention heads activate when a certain
  set of tokens are present in the text prompt. In contrast, self attentions activate
  irrrespective of text conditioning, since they attend to the visual aspects a concept. 
  </p>
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/attentions.png" style="width:100%; max-width:500px"></center>
    <figcaption> Cross attentions activate only when <b><i>"car"</i></b> is present
      in the prompt. But self attentions are activate in both the cases.
    </figcaption>
  </figure>
    
  <p>
  Inspired by this observation, we propose ESD-x, applying the erasing method to only
  fine tuning cross attention parameters while erasing a concept.  That has a very
  narrow effect on the output distribution, focusing changes on conditions when
  the concept is explicitly mentioned in the prompt. Such finer effects are desirable
  in case of artistic style erasure, where some artists may wish to have their styles
  be preserved while others erased.  We also study ESD-u, which is fine tuning all the
  unconditional layers (all layers except cross-attentions), which creates a generalised
  erasure of a concept that does not depend on the presence of specific words in the prompt;
  this is useful when removing NSFW output in a way that includes situations where NSFW
  terms are not used in the prompt.
  </p>   
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/ablation.png" style="width:100%; max-width:800px"></center>
    <figcaption> ESD-x (last column) erases a concept narrowly while minimizing interference (last 3 rows), whereas ESD-u (third column) erases a concept broadly.
    </figcaption>
  </figure>
  
 <h2>Erasing an artistic style</h2>
      <p>We study artistic style erasure; our paper includes a user study where we
      measure compare the effects of using our method to erase an artistic style
      with other approaches including negative guidance and Safe Latent Diffusion.
      We also measure the interference effects of removing one style on other styles.
      </p>
      <figure class="center_image" style="margin-top: 30px">
        <center><img src="images/paper/artstyle.png" style="width:100%; max-width:800px"></center>
        <figcaption> Our method erases a style while minimizing undesired interference
          on other styles.  The blue dotted images represent the intended erasure
          while the off-diagonal images represent undesired interference. 
        </figcaption>
      </figure>
  
  <h2>Erasing nudity</h2>
    <p> Since NSFW content can be generated without explicitly mentioning words
    such as <i>"nudity"</i>, we apply ESD-u to fine-tune unconditioned
    parameters of the model. In our paper we compare our method to both inference-based
    guidance (Safe Latent Diffusion, SLS), and training-based censorship (Stable Diffusion v2.0
    and v2.1), and find that our method is able to erase more inappropriate content.
    </p>
    <figure class="center_image" style="margin-top: 30px">
      <center><img src="images/paper/nudity.png" style="width:100%; max-width:800px"></center>
      <figcaption> Our method erases more nudity across categories compared
        to inference guidance (SLD) or models like Stable Diffusion V2.0 that are
        trained on NSFW filtered datasets.
      </figcaption>
    </figure>
      

  <h2>Limitations</h2>
    <p> 
    For both NSFW erasure and artistic style erasure, we find that our
    method is more effective than baseline approaches on erasing the targeted visual 
    concept, but when erasing large concepts such as entire object classes or
    some particular styles, our method can impose a trade-off between complete
    erasure of a visual concept and interference with other visual concepts. </p>     
      <figure class="center_image" style="margin-top: 30px">
        <center><img src="images/paper/limitations.png" style="width:100%; max-width:600px"></center>
        <figcaption> Cases of incomplete concept erasures and style interference with our method.
        </figcaption>
      </figure>
  
<h2> More results on artistic style erasure </h2>
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/famous.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing famous styles. The blue dotted boxes show images with intended style erased. The off-diagonal images show the unintended interference. 
    </figcaption>
  </figure>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/niche2.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing specific artists. The blue dotted boxes show images with intended style erased. The off-diagonal images show the unintended interference. 
    </figcaption>
  </figure>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/niche1.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing specific artists. The blue dotted boxes show images with intended style erased. The off-diagonal images show the unintended interference. 
    </figcaption>
  </figure>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/niche3.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing specific artists. The blue dotted boxes show images with intended style erased. The off-diagonal images show the unintended interference. 
    </figcaption>
  </figure>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/niche4.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing specific artists. The blue dotted boxes show images with intended style erased. The off-diagonal images show the unintended interference. 
    </figcaption>
  </figure>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/niche5.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing specific artists. The blue dotted boxes show images with intended style erased. The off-diagonal images show the unintended interference. 
    </figcaption>
  </figure>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/niche6.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing specific artists. The blue dotted boxes show images with intended style erased. The off-diagonal images show the unintended interference. 
    </figcaption>
  </figure>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/niche7.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing specific artists. The blue dotted boxes show images with intended style erased. The off-diagonal images show the unintended interference. 
    </figcaption>
  </figure>
  
<h2> More results on object erasure </h2>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/object-intended1.png" style="width:100%; max-width:800px"></center>
    <figcaption> We show the intended erasure of objects by our method (Part 1). The rows in red-dotted box represent erasure of an object while
      the row above each of the red boxes represent their corresponding original SD image using the same seed and prompts.
    </figcaption>
  </figure>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/object-intended2.png" style="width:100%; max-width:800px"></center>
    <figcaption>  We show the intended erasure of objects by our method (Part 2). The rows in red-dotted box represent erasure of an object while
      the row above each of the red boxes represent their corresponding original SD image using the same seed and prompts.
    </figcaption>
  </figure>  
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/object-interference.png" style="width:100%; max-width:800px"></center>
    <figcaption> Interference effects of object erasure. The first row represents the original SD generations. From the later rows, the diagonal
      images represent the intended erasures while the off-diagonal images represent the interference
    </figcaption>
  </figure>

<h2>Concurrent Work</h2>
<div class="card">
<div class="card-block">
<p style="text-indent: -3em; margin-left: 3em;" class="card-text clickselect">
Nupur Kumari, Bingliang Zhang, Sheng-Yu Wang, Eli Shechtman, Richard Zhang, Jun-Yan Zhu "<em><a href="https://www.cs.cmu.edu/~concept-ablation/">Ablating Concepts in Text-to-Image Diffusion Models</a></em>" arXiv preprint <nobr><a href="https://arxiv.org/abs/2303.13516">arXiv:2303.13516</a> (2023).</nobr>
</p>
</div>
</div>
  
<h2>How to cite</h2>

<p>The paper appeared at ICCV 2023. It can be cited as follows.
</p>

<div class="card">
<h3 class="card-header">bibliography</h3>
<div class="card-block">
<p style="text-indent: -3em; margin-left: 3em;" class="card-text clickselect">
Rohit Gandikota, Joanna Materzy&#324;ska, Jaden Fiotto-Kaufman, David Bau. "<em>Erasing Concepts from Diffusion Models.</em>" Proceedings of the 2023 IEEE International Conference on Computer Vision (ICCV 2023).
<!--arXiv preprint <nobr><a href="https://arxiv.org/abs/2303.07345">arXiv:2303.07345</a> (2023).</nobr>-->
</p>
</div>
<h3 class="card-header">bibtex</h3>
<div class="card-block">
<pre class="card-text clickselect">
<!--
@article{gandikota2023erasing,
  title={Erasing Concepts from Diffusion Models},
  author={Rohit Gandikota and Joanna Materzy\'nska and Jaden Fiotto-Kaufman and David Bau},
  journal={arXiv preprint arXiv:2303.07345},
  year={2023}
}
-->
@inproceedings{gandikota2023erasing,
  title={Erasing Concepts from Diffusion Models},
  author={Rohit Gandikota and Joanna Materzy\'nska and Jaden Fiotto-Kaufman and David Bau},
  booktitle={Proceedings of the 2023 IEEE International Conference on Computer Vision},
  year={2023}
}
</pre>
</div>
</div>
</p>

</div>
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://baulab.info/">About the Bau Lab</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
</script>
</html>

